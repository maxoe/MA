% !TeX root = thesis.tex
%% preliminaries.tex
%%

%% ==============
\chapter{Preliminaries\label{ch:preliminaries}}
%% ==============
In this chapter, we introduce our basic notations and discuss important algorithmic concepts on which the work of this thesis is based.

We define a weighted, directed graph $G$ as a tuple $G=(V,E,\mathfunction{len})$. $V$ is the set of nodes and $E$ the set of edges $(u,v) \subseteq V \times V$ between those nodes. The function $\mathfunction{len}$ is the weight function $\mathfunction{len}\colon E \rightarrow \mathbb{R}_{\ge 0}$ which assigns each edge a non-negative weight which we often also call length of an edge. A path $p$ in $G$ is defined as a sequence of nodes $p = \langle v_0,v_1,...,v_k \rangle$ with $(v_i,v_{i+1}) \in E$. For simplicity, we will reuse the same function $\mathfunction{len}$ which we use to denote the length of an edge, to denote the length of a path $p$ in $G$. The length of a path $\mathfunction{len}(p)$ is defined by the sum of the weights of the edges on the path $\mathfunction{len}(p) = \sum_{i=0}^{k-1}{\mathfunction{len}((v_i,v_{i+1}))}$. A path must not necessarily be simple, i.e. nodes can appear multiple times in the same path.

Given two nodes $s$ and $t$ in a graph, we denote the shortest distance between them as $\distance(s,t)$. The shortest distance between two nodes is the minimum length of a path between them. The problem of finding the shortest distance and an associated path between two nodes in a graph is called the shortest path problem which we often abbreviate as SPP. The problem of finding the shortest path between nodes in a road network can be formalized as solving the SPP on a weighted, directed graph. Each edge of the graph represents a road and each node represents an intersection. Unless stated otherwise, the length $\len$ of an edge $(u,v)$ will always correspond to the time it takes to travel from $u$ to $v$ on the road which the edge represents. A solution of the SPP then yields the shortest time between two intersections in the road network and the associated path between them.

Dijkstra's algorithm, published in 1959, solves the SPP \cite{dijkstra:1959}. It operates on the graph $G$ without any additionally information or precomputed data structures. It maintains a queue $Q$ of nodes with ascending tentative distance from the starting node $s$ and two arrays, a distance value $d[v]$ and a predecessor node $pred[v]$ for each node. At the beginning, $Q$ only contains the start node $s$ with the distance zero. The two arrays are initialized with $d[v]=\infty$ and $pred[v]=\bot$ except for $d[s]=0$ and $pred[s]=s$. Iteratively, the node $u$ with the minimum distance is removed from $Q$ and each outgoing edge $(u,v) \in E$ of $u$ is \emph{relaxed}. We call this process \emph{settling} a node $u$. Relaxing an edge $(u,v)$ consists of three steps: First, the sum $d[u] + \len((u,v))$ is calculated. Second, it is tested if the distance $d[v]$ can be improved by choosing $u$ as a predecessor. Finally, if that is the case, the queue key of the node $v$ is decreased. If $v$ is not contained in $Q$ yet, the node is inserted into $Q$. The search can be stopped if the target node $t$ was removed from the queue \cite{dijkstra:1959}.

For many practical applications and for large graphs, Dijkstra's algorithm is too slow. A common extension is the A* algorithm \cite{hart:1968}. A* uses a \emph{heuristic} which yields a lower bound for the distance from each node to the target node to direct the search towards the goal. With a tight heuristic, A* can significantly reduce the search space, i.e., the amount of nodes it touches during the search in comparison to Dijkstra's algorithm. In the route planning context, the term \emph{potential} is often used for the heuristic. We will denote the potential of a node $v$ to a node $t$ with $\potential_t(v)$.

To further reduce the search space, it is possible to run a \emph{bidirectional} search. A bidirectional search to solve the SPP from $s$ to $t$ on a graph $G$ consists of a forward search and a backward search. The forward search operates on $G$ with start node $s$ and target node $t$ and maintains a forward queue $\overrightarrow{Q}$, a forward distance array $\overrightarrow{d}[v]$, and a forward predecessor array $\overrightarrow{pred}[v]$. The backward search operates on a backward graph $\overleftarrow{G}$ with start node $t$ and target node $s$ and maintains a backward queue $\overleftarrow{Q}$, a backward distance array $\overleftarrow{d}[v]$, and a backward predecessor array $\overleftarrow{pred}[v]$. The backward graph is defined as the graph $G$ with inverted edges, i.e, $\overleftarrow{G} = (V,\overleftarrow{E},\overleftarrow{\mathfunction{len}})$ with $\overleftarrow{E} = \{(v,u) \in V \times V \mid (u,v) \in E\}$ and $\overleftarrow{\mathfunction{len}}(u,v) = \mathfunction{len}(v,u)$. Additionally, an array $d[v]$ is maintained for combined tentative distances of forward and backward search and is initialized with $\infty$ for all nodes. A value $d[v]$ constitutes the shortest known distance for an $s$-$t$ path using $v$.

Forward and backward search now alternately settle a node $v$. If $v$ was settled by both searches, forward and backward search met at $v$. The value $d[v]$ is updated to the sum of $\overrightarrow{d}[v] + \overleftarrow{d}[v]$ if it is an improvement over the old value, i.e., it yields a shorter distance for an $s$-$t$ path via $v$.

The bidirectional search only yields an advantage over a unidirectional search if the two searches are stopped earlier than in a unidirectional search. If not, the bidirectional search would simply execute the work of an $s$-$t$ search twice. Therefore, stronger stopping criteria are introduced. When introducing a strong stopping criterion for a bidirectional A* search, the stopping criterion also depends on the potential being used. The work of \cite{goldberg:2005a} introduces a potential and stopping criterion which leads to an improvement over a unidirectional A* search. If a forward potential $\overrightarrow{\potential}_t$ and a backward potential $\overleftarrow{\potential}_s$ is used for the forward and the backward search, the search can be stopped when the minimum key of the forward queue $\minKey(\overrightarrow{Q})$ or the minimum key of the backward queue $\minKey(\overrightarrow{Q})$ is greater than the currently known shortest distance between $s$ and $t$. If $\overrightarrow{\potential}_t + \overleftarrow{\potential}_s \equiv const.$ holds for the potentials, then the search can be stopped when $\minKey(\overrightarrow{Q}) + \minKey(\overleftarrow{Q})$ exceeds the shortest know distance between $s$ and $t$.

\section{Contraction Hierarchies\label{sec:ch}}
Road networks have strong hierarchies since some roads are more important than others. For example, a highway allows high average speeds and therefore is a preferred connection between points in a road network in comparison to smaller roads. Contraction Hierarchies \cite{geisberger:2012} are a speed-up technique which exploits these hierarchies.

Contraction Hierarchies (CH) use a two phase approach. In the preprocessing phase, the CH is constructed given a graph $G=(V,E,\len)$ and a node order which sorts the nodes by importance. For example, an important node of a road network might be a node in a highway interchange, an unimportant node might be the head of a dead end. We denote the CH as $\ch$. The node order can be computed by searching for unimportant nodes \cite{geisberger:2012} or for important nodes first \cite{abraham:2012,delling:2014}. The nodes then are sorted into multiple levels of increasing importance. Two nodes of the same level must not have an edge between them. We obtain the CH $\ch$ by iteratively contracting the least important node according to the node order by adding shortcut edges between its neighbors.

An outgoing edge of a node to another node of a higher level is called an \emph{upward} edge, the opposite is called a \emph{downward} edge. A path which consists of only upward edges is called an \emph{up-path}, a path which consists of only downward edges is called a \emph{down-path}. Finally, a path which consists of an up-path, followed by a down-path, is called an \emph{up-down-path}. The node on an up-down-path with the highest level, i.e. the node which separates up-path and down-path, is called the \emph{middle node} $m$ of the path.

For every shortest path between node $s,t \in V$, there exists an up-down $s$-$m$-$t$ path in $\ch$ of the exact same length \cite{geisberger:2012}. Therefore, we can restrict the search to finding this exact path. We run a bidirectional search from $s$ and $t$. The forward search from $s$ may only use upward edges and finds the subpath $s$-$m$, the backward search from $t$ may only use the inverted downward edges and finds the subpath $m$-$t$. The search is stopped if the minimum queue key of both queues of forward and backward search is greater or equal to the tentative minimum distance $\distance(s,t)$ \cite{geisberger:2012}.


\section{Core Contraction Hierarchies\label{sec:core_ch}}
The core contraction hierarchy presents a compromise between constructing a full CH $\ch$ and running a bidirectional search on $G$. The core CH $\corech$ is obtained by stopping the iterative contraction of nodes of increasing importance during the construction of the CH early. This leads to a set $C \subseteq V$ of so-called core nodes which are uncontracted. The set of nodes $V$ therefore is separated into a set of core nodes $C$ and a set of contracted nodes $\chv = V \setminus C$. The graph $\ch = (\chv,\che,\mathfunction{len})$ therefore is a valid contraction hierarchy. It contains only contracted nodes and (shortcut) edges between those nodes. The graph $G_{C} = (V \setminus \chv,E \setminus \che,\mathfunction{len})$ is called the core graph.

The core CH query again is a bidirectional search from $s$ and $t$. The query represents a normal CH query while settling nodes $v \in \chv$, i.e., it consists of a forward search from $s$ using only upward edges and a backward search from $t$ using only inverted downward edges. If a search reaches an uncontracted core node, it considers all outgoing edges. Thus, the core CH query can be characterized as a CH query in $\ch$ which transitions into a full bidirectional search if it reaches the core $G_C$. We can use the same stopping criterion as for the CH query since the stopping criterion for a CH is more conservative than the stopping criterion for a pure bidirectional search.


\section{CH-Potentials\label{sec:ch_pot}}
CH-Potentials \cite{strasser:2021b} are an extension of CH to efficiently calculate distances $\distance(v,t)$ for many nodes $v \in V$ to a fixed node $t$. CH-Potentials are based on PHAST \cite{delling:2011} which itself is an extension of CH to efficiently run all-to-one queries.

PHAST runs in two steps. The first step is a backward one-to-all search from $t$ using only inverted downward edges. This is the same as running the backward search of a CH query from $t$ without any stopping criterion. We obtain an array $B$ where $B[v]$ is the length of the shortest down path from $v$ to $t$ or $B[v]=\infty$ if there is no such path. We then iteratively calculate the distance $\distance(v,t)$ of nodes of the same level, starting at the highest level. This is possible since nodes of the same level must not have edges between them. To obtain the distances of nodes $u$ of the next lower level, we find the minimum $\min(B[u], \min_v(\len(u,v) + \distance(v,t)))$ for all upward edges $(u,v)$ of the node $v$. The distances $\distance(v,t)$ were already computed in the previous iteration.

We can use PHAST as to compute potentials if we run its two steps beforehand as a preprocessing step and then look up the respective distances. This preprocessing would be slow since it computes the distances to all nodes. CH-Potentials mitigate this problem by computing the results of the second PHAST step lazily while the first step remains the same. We do not calculate the distances of all nodes beforehand. To compute the potential of a node $u$, we recursively compute the potential for all nodes $v$ which are connected to $u$ by upward edges $(u,v) \in \che$. We then can compute the distance to $t$ as in the PHAST algorithm by finding $\min(B[u], \min_v(\len(u,v) + \distance(v,t)))$. We save all the calculated distances $\distance(v,t)$ in order to not compute any distance value twice.

CH-Potentials can be optimized further as \cite{strasser:2021b} describes in detail.