%% preliminaries.tex
%%

%% ==============
\chapter{Preliminaries and Related Work}
\label{ch:preliminaries}
%% ==============
In this chapter, we will introduce our basic notation and discuss important algorithmic concepts on which the work of this thesis is based.

We define a weighted, directed graph $G$ as a tuple $G=(V,E,\mathfunction{len})$. $V$ is the set of vertices and $E$ the set of edges $(u,v) \subseteq V \times V$ between those vertices. The function $\mathfunction{len}$ is the weight function $\mathfunction{len}\colon E \rightarrow \mathbb{R}_{\ge 0}$ which assigns each edge a non-negative weight which we often also call length of an edge. A path $p$ in $G$ is defined as a sequence of nodes $p = \langle v_0,v_1,...,v_k \rangle$ with $(v_i,v_{i+1}) \in E$. For simplicity, we will reuse the same function $\mathfunction{len}$ which we use to denote the length of an edge, to denote the length of a path $p$ in $G$. The length of a path $\mathfunction{len}(p)$ is defined by the sum of the weights of the edges on the path $\mathfunction{len}(p) = \sum_{i=0}^{k-1}{\mathfunction{len}((v_i,v_{i+1}))}$. A path must not necessarily be simple, i.e. nodes can appear multiple times in the same path.

Given two nodes $s$ and $t$ in a graph, we denote the shortest distance between them as $\distance(s,t)$. The shortest distance between two nodes is the minimum length of a path between them. The problem of finding the shortest distance between two nodes in a graph is called the shortest path problem which we often abbreviate as SPP. The problem of finding a fast path through a road network can be formalized as solving the SPP on a weighted graph. Each edge of the graph represents a road and each node represents an intersection. Unless stated otherwise, the length \mathfunction{len} of an edge $(u,v)$ will always correspond to the time it takes to travel from $u$ to $v$ on the road which the edge represents. A solution of the SPP then yields the shortest time between to intersections in the road network and a path between them.

Dijkstra's algorithm, published in 1959, solves the SPP \cite{dijkstra:1959}. It operates on the graph G without any additionally information or precomputed data structures. It maintains a queue $Q$ of nodes with ascending tentative distance from the starting node $s$ and two arrays, a distance value $d[v]$ and a predecessor node $pred[v]$ for each node. At the beginning, $Q$ only contains the start node $s$ with the distance zero. The two arrays are initialized with $d[v]=\infty$ and $pred[v]=\bot$ except for $d[s]=0$ and $pred[s]=s$. Iteratively, the node $u$ with the minimum distance is removed from $Q$ and each outgoing edge $(u,v) \in E$ of $u$ is \emph{relaxed}. We call this process \emph{settling} a node $u$. Relaxing an edge $(u,v)$ consists of three steps: First, the sum $d[u] + \len((u,v))$ is calculated. Second, it is tested if the distance $d[v]$ can be improved by choosing $u$ as a predecessor. Finally, if that is the case, the queue key of the node $v$ is decreased. If $v$ is not contained in $Q$ yet, the node is inserted into $Q$. The search can be stopped if the target node $t$ was removed from the queue \cite{dijkstra:1959}.

For many practical applications and for large graphs, Dijkstra's algorithm is too slow. A common extension is the A* algorithm \cite{hart:1968}. A* uses a \emph{heuristic} which yields a lower bound for the distance from each node to the target node to direct the search towards the goal. With a tight heuristic, A* can significantly reduce the search space, i.e., the amount of nodes it touches during the search in comparison to Dijkstra's algorithm. In the route planning context, the heuristic often is called \emph{potential}. We will denote the potential of a node $v$ to a node $t$ with $\potential_t(v)$.

To further reduce the search space, it is possible to run a \emph{bidirectional} search. A bidirectional search to solve the SPP from $s$ to $t$ on a graph $G$ consists of a forward search and a backward search. The forward search operates on $G$ with start node $s$ and target node $t$ and maintains a forward queue $\overrightarrow{Q}$, a forward distance array $\overrightarrow{d}[v]$, and a forward predecessor array $\overrightarrow{pred}[v]$. The backward search operates on a backward graph $\overleftarrow{G}$ with start node $t$ and target node $s$ and maintains a backward queue $\overleftarrow{Q}$, a backward distance array $\overleftarrow{d}[v]$, and a backward predecessor array $\overleftarrow{pred}[v]$. The backward graph is defined as the graph $G$ with inverted edges, i.e, $\overleftarrow{G} = (V,\overleftarrow{E},\overleftarrow{\mathfunction{len}})$ with $\overleftarrow{E} = \{(v,u) \in V \times V \mid (u,v) \in E\}$ and $\overleftarrow{\mathfunction{len}}(u,v) = \mathfunction{len}(v,u)$. Additionally, an array $d[v]$ is maintained for combined tentative distances of forward and backward search and is initialized with $\infty$ for all nodes. A value $d[v]$ constitutes the shortest known distance for an $s$-$t$ path using $v$.

Forward and backward search now alternatively settle a node $v$. If $v$ was settled by both searches, forward and backward search met at $v$. The value $d[v]$ is updated to the sum of $\overrightarrow{d}[v] + \overleftarrow{d}[v]$ if it is an improvement over the old value, i.e., it yields a shorter distance for an $s$-$t$ path via $v$.

The bidirectional search only yields an advantage over a unidirectional search if the two searches are stopped earlier than in a unidirectional search. If not, the bidirectional search would only execute the work of an $s$-$t$ search twice. Therefore, stronger stopping criteria are introduced. When introducing a strong stopping criterion for a bidirectional A* search, the stopping criterion also depends on the potential function being used. The work of \cite{goldberg:2005} introduces a potential and stopping criterion which leads to an improvement over a unidirectional A* search.

\section{Contraction Hierarchies}
\label{sec:ch}
\section{CH Potential\label{sec:ch_pot}}
\section{Core Contraction Hierarchies}